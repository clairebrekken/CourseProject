{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas                        as     pd\n",
    "import numpy                         as     np\n",
    "import seaborn                       as     sns\n",
    "import os \n",
    "import matplotlib.pyplot             as     plt\n",
    "from   utils_text_clf                import utils_text_clf as utils\n",
    "from   sklearn.feature_selection     import f_classif, \\\n",
    "                                            VarianceThreshold, \\\n",
    "                                            SelectKBest\n",
    "from   sklearn.model_selection       import StratifiedKFold, \\\n",
    "                                            RepeatedStratifiedKFold, \\\n",
    "                                            cross_validate, \\\n",
    "                                            cross_val_predict, \\\n",
    "                                            GridSearchCV, \\\n",
    "                                            train_test_split\n",
    "from   sklearn.pipeline              import Pipeline, \\\n",
    "                                            make_pipeline\n",
    "from   sklearn.preprocessing         import StandardScaler, \\\n",
    "                                            RobustScaler, \\\n",
    "                                            MinMaxScaler\n",
    "from   sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from   sklearn.tree                  import DecisionTreeClassifier\n",
    "from   sklearn.linear_model          import LogisticRegression, \\\n",
    "                                            SGDClassifier\n",
    "from   sklearn.svm                   import LinearSVC, SVC\n",
    "from   sklearn.neighbors             import KNeighborsClassifier\n",
    "from   sklearn.naive_bayes           import GaussianNB\n",
    "from   sklearn.ensemble              import RandomForestClassifier, \\\n",
    "                                            AdaBoostClassifier, \\\n",
    "                                            GradientBoostingClassifier, \\\n",
    "                                            StackingClassifier\n",
    "from   mlxtend.classifier            import StackingClassifier as mlx_stack_clf\n",
    "from   sklearn.manifold              import TSNE\n",
    "from   sklearn.decomposition         import PCA\n",
    "import xgboost                       as     xgb\n",
    "from   sklearn.metrics               import roc_curve\n",
    "from   scipy                         import interp\n",
    "from   pathlib                       import Path\n",
    "from   pickle                        import dump\n",
    "import joblib\n",
    "\n",
    "# Turn interactive plotting off\n",
    "plt.ion()  \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enter mutable info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Enter mutable info\n",
    "\n",
    "data_dir    = os.path.join(os.getcwd(), 'data')\n",
    "results_dir = os.path.join(os.getcwd(), 'results')\n",
    "\n",
    "# training data \n",
    "#file_train = 'train.jsonl'\n",
    "\n",
    "# training data\n",
    "file_train  = 'train_feature_engineering.csv';\n",
    "file_test   = 'test_feature_engineering.csv'\n",
    "\n",
    "#file_train = os.path.join(data_dir, file_train) \n",
    "file_train  = os.path.join(data_dir, file_train) \n",
    "file_test   = os.path.join(data_dir, file_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% load in data \n",
    "\n",
    "#df_train = utils.parse_json(file_train)\n",
    "df_train  = pd.read_csv(file_train)\n",
    "\n",
    "# feats\n",
    "x_train  = df_train.iloc[:, 1:]\n",
    "\n",
    "# labels \n",
    "y_train  = df_train.label\n",
    "\n",
    "# convert labels to binary (1 - sarcasm)\n",
    "y_train  = [1 if i == 'SARCASM' else 0 for i in y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The count of sarcastic tweets is: 2500\n",
      "The count of non-sarcastic tweets is: 2500\n"
     ]
    }
   ],
   "source": [
    "#%% check label proportions \n",
    "\n",
    "# print count\n",
    "print('The count of sarcastic tweets is:', y_train.count(1))\n",
    "print('The count of non-sarcastic tweets is:', y_train.count(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 29)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the size of the training data \n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>users_tagged</th>\n",
       "      <th>num_hashtags</th>\n",
       "      <th>num_capital</th>\n",
       "      <th>tweet_length_words</th>\n",
       "      <th>tweet_length_char</th>\n",
       "      <th>average_token_length</th>\n",
       "      <th>contains_laughter</th>\n",
       "      <th>contains_ellipses</th>\n",
       "      <th>strong_negations</th>\n",
       "      <th>strong_affirmatives</th>\n",
       "      <th>...</th>\n",
       "      <th>context_tweet_length_char</th>\n",
       "      <th>context_average_token_length</th>\n",
       "      <th>context_contains_laughter</th>\n",
       "      <th>context_contains_ellipses</th>\n",
       "      <th>context_strong_negations</th>\n",
       "      <th>context_strong_affirmatives</th>\n",
       "      <th>context_interjections</th>\n",
       "      <th>context_intensifiers</th>\n",
       "      <th>context_punctuation</th>\n",
       "      <th>context_emojis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.947200</td>\n",
       "      <td>0.733800</td>\n",
       "      <td>5.856000</td>\n",
       "      <td>25.357800</td>\n",
       "      <td>100.386400</td>\n",
       "      <td>0.255635</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>0.165800</td>\n",
       "      <td>0.209800</td>\n",
       "      <td>0.178600</td>\n",
       "      <td>...</td>\n",
       "      <td>561.159000</td>\n",
       "      <td>0.782949</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.998800</td>\n",
       "      <td>1.212000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.933266</td>\n",
       "      <td>1.059227</td>\n",
       "      <td>8.217638</td>\n",
       "      <td>13.401869</td>\n",
       "      <td>51.590365</td>\n",
       "      <td>0.042288</td>\n",
       "      <td>0.184886</td>\n",
       "      <td>0.479538</td>\n",
       "      <td>0.491765</td>\n",
       "      <td>0.438566</td>\n",
       "      <td>...</td>\n",
       "      <td>537.603877</td>\n",
       "      <td>0.658256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.286359</td>\n",
       "      <td>4.211865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.117117</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>0.281854</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>0.404089</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>0.253012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>0.547531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>122.250000</td>\n",
       "      <td>0.279570</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>630.000000</td>\n",
       "      <td>0.854243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>238.000000</td>\n",
       "      <td>0.522727</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5788.000000</td>\n",
       "      <td>5.404175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       users_tagged  num_hashtags  num_capital  tweet_length_words  \\\n",
       "count   5000.000000   5000.000000  5000.000000         5000.000000   \n",
       "mean       1.947200      0.733800     5.856000           25.357800   \n",
       "std        0.933266      1.059227     8.217638           13.401869   \n",
       "min        0.000000      0.000000     0.000000            8.000000   \n",
       "25%        1.000000      0.000000     2.000000           16.000000   \n",
       "50%        2.000000      0.000000     4.000000           21.000000   \n",
       "75%        3.000000      1.000000     7.000000           31.000000   \n",
       "max        4.000000      3.000000   165.000000           77.000000   \n",
       "\n",
       "       tweet_length_char  average_token_length  contains_laughter  \\\n",
       "count        5000.000000           5000.000000        5000.000000   \n",
       "mean          100.386400              0.255635           0.032000   \n",
       "std            51.590365              0.042288           0.184886   \n",
       "min            24.000000              0.117117           0.000000   \n",
       "25%            64.000000              0.227273           0.000000   \n",
       "50%            86.000000              0.253012           0.000000   \n",
       "75%           122.250000              0.279570           0.000000   \n",
       "max           238.000000              0.522727           2.000000   \n",
       "\n",
       "       contains_ellipses  strong_negations  strong_affirmatives  ...  \\\n",
       "count        5000.000000       5000.000000          5000.000000  ...   \n",
       "mean            0.165800          0.209800             0.178600  ...   \n",
       "std             0.479538          0.491765             0.438566  ...   \n",
       "min             0.000000          0.000000             0.000000  ...   \n",
       "25%             0.000000          0.000000             0.000000  ...   \n",
       "50%             0.000000          0.000000             0.000000  ...   \n",
       "75%             0.000000          0.000000             0.000000  ...   \n",
       "max             5.000000          4.000000             4.000000  ...   \n",
       "\n",
       "       context_tweet_length_char  context_average_token_length  \\\n",
       "count                5000.000000                   5000.000000   \n",
       "mean                  561.159000                      0.782949   \n",
       "std                   537.603877                      0.658256   \n",
       "min                    86.000000                      0.281854   \n",
       "25%                   250.000000                      0.404089   \n",
       "50%                   392.000000                      0.547531   \n",
       "75%                   630.000000                      0.854243   \n",
       "max                  5788.000000                      5.404175   \n",
       "\n",
       "       context_contains_laughter  context_contains_ellipses  \\\n",
       "count                     5000.0                     5000.0   \n",
       "mean                         0.0                        0.0   \n",
       "std                          0.0                        0.0   \n",
       "min                          0.0                        0.0   \n",
       "25%                          0.0                        0.0   \n",
       "50%                          0.0                        0.0   \n",
       "75%                          0.0                        0.0   \n",
       "max                          0.0                        0.0   \n",
       "\n",
       "       context_strong_negations  context_strong_affirmatives  \\\n",
       "count                    5000.0                       5000.0   \n",
       "mean                        0.0                          0.0   \n",
       "std                         0.0                          0.0   \n",
       "min                         0.0                          0.0   \n",
       "25%                         0.0                          0.0   \n",
       "50%                         0.0                          0.0   \n",
       "75%                         0.0                          0.0   \n",
       "max                         0.0                          0.0   \n",
       "\n",
       "       context_interjections  context_intensifiers  context_punctuation  \\\n",
       "count                 5000.0                5000.0          5000.000000   \n",
       "mean                     0.0                   0.0             1.998800   \n",
       "std                      0.0                   0.0             3.286359   \n",
       "min                      0.0                   0.0             0.000000   \n",
       "25%                      0.0                   0.0             0.000000   \n",
       "50%                      0.0                   0.0             1.000000   \n",
       "75%                      0.0                   0.0             3.000000   \n",
       "max                      0.0                   0.0            70.000000   \n",
       "\n",
       "       context_emojis  \n",
       "count     5000.000000  \n",
       "mean         1.212000  \n",
       "std          4.211865  \n",
       "min          0.000000  \n",
       "25%          0.000000  \n",
       "50%          0.000000  \n",
       "75%          1.000000  \n",
       "max         80.000000  \n",
       "\n",
       "[8 rows x 29 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove features with 0 variance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector_var = VarianceThreshold()\n",
    "\n",
    "# select feats with var > 0\n",
    "selector_var.fit(x_train)\n",
    "\n",
    "# filter \n",
    "x_train = x_train[x_train.columns[selector_var.get_support(indices = True)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>users_tagged</th>\n",
       "      <th>num_hashtags</th>\n",
       "      <th>num_capital</th>\n",
       "      <th>tweet_length_words</th>\n",
       "      <th>tweet_length_char</th>\n",
       "      <th>average_token_length</th>\n",
       "      <th>contains_laughter</th>\n",
       "      <th>contains_ellipses</th>\n",
       "      <th>strong_negations</th>\n",
       "      <th>strong_affirmatives</th>\n",
       "      <th>...</th>\n",
       "      <th>punctuation</th>\n",
       "      <th>emojis</th>\n",
       "      <th>ngram_feature</th>\n",
       "      <th>context_users_tagged</th>\n",
       "      <th>context_num_hashtags</th>\n",
       "      <th>context_tweet_length_words</th>\n",
       "      <th>context_tweet_length_char</th>\n",
       "      <th>context_average_token_length</th>\n",
       "      <th>context_punctuation</th>\n",
       "      <th>context_emojis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>99</td>\n",
       "      <td>0.252525</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>281</td>\n",
       "      <td>0.390073</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>88</td>\n",
       "      <td>0.238636</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>126</td>\n",
       "      <td>0.429294</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>73</td>\n",
       "      <td>0.191781</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>196</td>\n",
       "      <td>0.453922</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>108</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>304</td>\n",
       "      <td>0.361325</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>30</td>\n",
       "      <td>143</td>\n",
       "      <td>0.209790</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>316</td>\n",
       "      <td>0.430424</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   users_tagged  num_hashtags  num_capital  tweet_length_words  \\\n",
       "0             3             0            1                  25   \n",
       "1             2             0            4                  21   \n",
       "2             3             1           13                  14   \n",
       "3             2             0            6                  21   \n",
       "4             2             3           22                  30   \n",
       "\n",
       "   tweet_length_char  average_token_length  contains_laughter  \\\n",
       "0                 99              0.252525                  0   \n",
       "1                 88              0.238636                  0   \n",
       "2                 73              0.191781                  0   \n",
       "3                108              0.194444                  0   \n",
       "4                143              0.209790                  0   \n",
       "\n",
       "   contains_ellipses  strong_negations  strong_affirmatives  ...  punctuation  \\\n",
       "0                  3                 0                    0  ...            3   \n",
       "1                  0                 0                    0  ...            1   \n",
       "2                  0                 0                    0  ...            1   \n",
       "3                  0                 0                    1  ...            0   \n",
       "4                  0                 0                    0  ...            0   \n",
       "\n",
       "   emojis  ngram_feature  context_users_tagged  context_num_hashtags  \\\n",
       "0       0           31.0                     1                     1   \n",
       "1       0           27.0                     4                     0   \n",
       "2       0           14.0                     1                     0   \n",
       "3       0           25.0                     1                     0   \n",
       "4       0           34.0                     1                     0   \n",
       "\n",
       "   context_tweet_length_words  context_tweet_length_char  \\\n",
       "0                          55                        281   \n",
       "1                          27                        126   \n",
       "2                          44                        196   \n",
       "3                          56                        304   \n",
       "4                          63                        316   \n",
       "\n",
       "   context_average_token_length  context_punctuation  context_emojis  \n",
       "0                      0.390073                    0               1  \n",
       "1                      0.429294                    1               0  \n",
       "2                      0.453922                    0               0  \n",
       "3                      0.361325                    0               0  \n",
       "4                      0.430424                    0               0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#==========================================================================================\n",
    "#   _____          _          __     __    _ _     _       _         ____        _ _ _   \n",
    "#  |_   _| __ __ _(_)_ __     \\ \\   / /_ _| (_) __| | __ _| |_ ___  / ___| _ __ | (_) |_ \n",
    "#    | || '__/ _` | | '_ \\ ____\\ \\ / / _` | | |/ _` |/ _` | __/ _ \\ \\___ \\| '_ \\| | | __|\n",
    "#    | || | | (_| | | | | |_____\\ V / (_| | | | (_| | (_| | ||  __/  ___) | |_) | | | |_ \n",
    "#    |_||_|  \\__,_|_|_| |_|      \\_/ \\__,_|_|_|\\__,_|\\__,_|\\__\\___| |____/| .__/|_|_|\\__|\n",
    "#                                                                         |_|            \n",
    "#=========================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and validation set \n",
    "x_train_sub, x_val, y_train_sub, y_val = train_test_split(x_train, \n",
    "                                                          y_train, \n",
    "                                                          test_size    = 0.3, \n",
    "                                                          random_state = 42, \n",
    "                                                          stratify     = y_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#===============================================================\n",
    "#  _   _                                                       \n",
    "# | | | |_   _ _ __   ___ _ __ _ __   __ _ _ __ __ _ _ __ ___  \n",
    "# | |_| | | | | '_ \\ / _ \\ '__| '_ \\ / _` | '__/ _` | '_ ` _ \\ \n",
    "# |  _  | |_| | |_) |  __/ |  | |_) | (_| | | | (_| | | | | | |\n",
    "# |_|_|_|\\__, | .__/_\\___|_|  | .__/ \\__,_|_|  \\__,_|_| |_| |_|\n",
    "# |_   _||___/|_|_ (_)_ __   _|_|                              \n",
    "#   | || | | | '_ \\| | '_ \\ / _` |                             \n",
    "#   | || |_| | | | | | | | | (_| |                             \n",
    "#   |_| \\__,_|_| |_|_|_| |_|\\__, |                             \n",
    "#                           |___/                              \n",
    "#==============================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common params \n",
    "\n",
    "# define scalers to try\n",
    "scalers     = [StandardScaler(), \n",
    "               RobustScaler(), \n",
    "               MinMaxScaler()]\n",
    "\n",
    "# define cross-val method\n",
    "cv          = StratifiedKFold(n_splits     = 10, \n",
    "                              shuffle      = True, \n",
    "                              random_state = 42)\n",
    "\n",
    "# define scoring metric\n",
    "metric      = 'f1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    5.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuning log_reg clf complete\n",
      "Best parameters: {'classifier': LogisticRegression(C=0.1519911082952933, class_weight='balanced',\n",
      "                   max_iter=20000, n_jobs=-1, random_state=42), 'classifier__C': 0.1519911082952933, 'classifier__class_weight': 'balanced', 'classifier__max_iter': 20000, 'classifier__penalty': 'l2', 'scaler': RobustScaler()}\n",
      "Mean cross-validated F1: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed:    8.7s finished\n"
     ]
    }
   ],
   "source": [
    "#%% log_reg clf\n",
    "\n",
    "# base clf\n",
    "logreg_clf    = LogisticRegression(n_jobs       = -1, \n",
    "                                   class_weight = 'balanced', \n",
    "                                   random_state = 42)\n",
    "\n",
    "# create model pipeline \n",
    "pipe_logreg   = Pipeline([('scaler',     StandardScaler()),\n",
    "                          ('classifier', logreg_clf)])\n",
    "\n",
    "# define param grid\n",
    "params_logreg = {'scaler'                   : scalers,\n",
    "                 'classifier'               : [logreg_clf],\n",
    "                 'classifier__penalty'      : ['l2'],\n",
    "                 'classifier__C'            : np.logspace(-3, 3, 12),\n",
    "                 'classifier__max_iter'     : [20000], \n",
    "                 'classifier__class_weight' : ['balanced']}\n",
    "\n",
    "grid_logreg   = GridSearchCV(pipe_logreg, \n",
    "                             cv                 = cv, \n",
    "                             param_grid         = params_logreg, \n",
    "                             scoring            = metric,\n",
    "                             refit              = True, \n",
    "                             return_train_score = False, \n",
    "                             n_jobs             = -1, \n",
    "                             verbose            = 1)\n",
    "\n",
    "# perform tuning and extract best model\n",
    "best_logreg = grid_logreg.fit(x_val, y_val).best_estimator_\n",
    "\n",
    "print('tuning log_reg clf complete')\n",
    "print('Best parameters: %s' % grid_logreg.best_params_)\n",
    "print('Mean cross-validated F1: %.2f' % grid_logreg.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1013 tasks      | elapsed:   18.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1338 tasks      | elapsed:  1.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuning svc_lin clf complete\n",
      "Best parameters: {'classifier': LinearSVC(C=23.10129700083158, class_weight='balanced', loss='hinge',\n",
      "          max_iter=20000, random_state=42), 'classifier__C': 23.10129700083158, 'classifier__class_weight': 'balanced', 'classifier__loss': 'hinge', 'classifier__max_iter': 20000, 'classifier__penalty': 'l2', 'scaler': MinMaxScaler()}\n",
      "Mean cross-validated F1: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1440 out of 1440 | elapsed:  1.5min finished\n"
     ]
    }
   ],
   "source": [
    "#%% svc_lin\n",
    "\n",
    "# base clf\n",
    "svc_lin_clf    = LinearSVC(max_iter     = 20000, \n",
    "                           class_weight = 'balanced', \n",
    "                           random_state = 42)\n",
    "\n",
    "# create model pipeline \n",
    "pipe_svc_lin   = Pipeline([('scaler',     StandardScaler()),\n",
    "                           ('classifier', svc_lin_clf)])\n",
    "\n",
    "# define param grid\n",
    "params_svc_lin = {'scaler'                   : scalers,\n",
    "                  'classifier'               : [svc_lin_clf],\n",
    "                  'classifier__penalty'      : ['l1', 'l2'],\n",
    "                  'classifier__loss'         : ['hinge', 'squared_hinge'],\n",
    "                  'classifier__C'            : np.logspace(-3, 3, 12),\n",
    "                  'classifier__max_iter'     : [20000], \n",
    "                  'classifier__class_weight' : ['balanced']}\n",
    "\n",
    "grid_svc_lin   = GridSearchCV(pipe_svc_lin, \n",
    "                              cv                 = cv, \n",
    "                              param_grid         = params_svc_lin, \n",
    "                              scoring            = metric,\n",
    "                              refit              = True, \n",
    "                              return_train_score = False, \n",
    "                              n_jobs             = -1, \n",
    "                              verbose            = 1)\n",
    "\n",
    "# perform tuning and extract best model\n",
    "best_svc_lin   = grid_svc_lin.fit(x_val, y_val).best_estimator_\n",
    "\n",
    "print('tuning svc_lin clf complete')\n",
    "print('Best parameters: %s' % grid_svc_lin.best_params_)\n",
    "print('Mean cross-validated F1: %.2f' % grid_svc_lin.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    0.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuning sgd clf complete\n",
      "Best parameters: {'classifier': SGDClassifier(class_weight='balanced', early_stopping=True, loss='log',\n",
      "              max_iter=20000, penalty='l1', tol=0.0001), 'classifier__loss': 'log', 'classifier__penalty': 'l1', 'scaler': MinMaxScaler()}\n",
      "Mean cross-validated F1: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 344 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed:    2.5s finished\n"
     ]
    }
   ],
   "source": [
    "#%% sgd clf\n",
    "\n",
    "# base clf\n",
    "sgd_clf      = SGDClassifier(max_iter       = 20000,\n",
    "                             tol            = 1e-4, \n",
    "                             class_weight   = 'balanced', \n",
    "                             early_stopping = True)\n",
    "\n",
    "# create model pipeline \n",
    "pipe_sgd     = Pipeline([('scaler',     StandardScaler()),\n",
    "                         ('classifier', sgd_clf)])\n",
    "\n",
    "# define param grid\n",
    "params_sgd   = {'scaler'                   : scalers,\n",
    "                'classifier'               : [sgd_clf],\n",
    "                'classifier__penalty'      : ['l1', 'l2', 'elasticnet'],\n",
    "                'classifier__loss'         : ['hinge', 'squared_hinge', 'log', 'perceptron']}\n",
    "\n",
    "grid_sgd     = GridSearchCV(pipe_sgd, \n",
    "                            cv                 = cv, \n",
    "                            param_grid         = params_sgd, \n",
    "                            scoring            = metric,\n",
    "                            refit              = True, \n",
    "                            return_train_score = False, \n",
    "                            n_jobs             = -1, \n",
    "                            verbose            = 1)\n",
    "\n",
    "# perform tuning and extract best model\n",
    "best_sgd     = grid_sgd.fit(x_val, y_val).best_estimator_\n",
    "\n",
    "print('tuning sgd clf complete')\n",
    "print('Best parameters: %s' % grid_sgd.best_params_)\n",
    "print('Mean cross-validated F1: %.2f' % grid_sgd.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 900 candidates, totalling 9000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1640 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done 3712 tasks      | elapsed:   15.0s\n",
      "[Parallel(n_jobs=-1)]: Done 7312 tasks      | elapsed:   31.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuning lda clf complete\n",
      "Best parameters: {'classifier': LinearDiscriminantAnalysis(shrinkage=0.07, solver='lsqr'), 'classifier__shrinkage': 0.07, 'classifier__solver': 'lsqr', 'scaler': RobustScaler()}\n",
      "Mean cross-validated F1: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 9000 out of 9000 | elapsed:   37.5s finished\n"
     ]
    }
   ],
   "source": [
    "#%% lda\n",
    "\n",
    "# base clf\n",
    "lda_clf      = LinearDiscriminantAnalysis()\n",
    "\n",
    "# create model pipeline \n",
    "pipe_lda     = Pipeline([('scaler',     StandardScaler()),\n",
    "                         ('classifier', lda_clf)])\n",
    "\n",
    "# define param grid\n",
    "params_lda   = {'scaler'                   : scalers,\n",
    "                'classifier'               : [lda_clf],\n",
    "                'classifier__solver'       : ['svd', 'lsqr', 'eigen'],\n",
    "                'classifier__shrinkage'    : np.arange(0, 1, 0.01)}\n",
    "\n",
    "grid_lda     = GridSearchCV(pipe_lda, \n",
    "                            cv                 = cv, \n",
    "                            param_grid         = params_lda, \n",
    "                            scoring            = metric,\n",
    "                            refit              = True, \n",
    "                            return_train_score = False, \n",
    "                            n_jobs             = -1, \n",
    "                            verbose            = 1)\n",
    "\n",
    "# perform tuning and extract best model\n",
    "best_lda     = grid_lda.fit(x_val, y_val).best_estimator_\n",
    "\n",
    "print('tuning lda clf complete')\n",
    "print('Best parameters: %s' % grid_lda.best_params_)\n",
    "print('Mean cross-validated F1: %.2f' % grid_lda.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "session saved!\n"
     ]
    }
   ],
   "source": [
    "# save session \n",
    "import dill \n",
    "dill.dump_session('dev_split_hparam_tuning_complete.db')\n",
    "print('session saved!')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#============================================================================================\n",
    "#   ____      _             _         _____ _             _   __  __           _      _     \n",
    "#  |  _ \\ ___| |_ _ __ __ _(_)_ __   |  ___(_)_ __   __ _| | |  \\/  | ___   __| | ___| |___ \n",
    "#  | |_) / _ \\ __| '__/ _` | | '_ \\  | |_  | | '_ \\ / _` | | | |\\/| |/ _ \\ / _` |/ _ \\ / __|\n",
    "#  |  _ <  __/ |_| | | (_| | | | | | |  _| | | | | | (_| | | | |  | | (_) | (_| |  __/ \\__ \\\n",
    "#  |_| \\_\\___|\\__|_|  \\__,_|_|_| |_| |_|   |_|_| |_|\\__,_|_| |_|  |_|\\___/ \\__,_|\\___|_|___/\n",
    "#\n",
    "#============================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrain best model on the **training subset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all done!\n"
     ]
    }
   ],
   "source": [
    "# hyperparam tuned models \n",
    "\n",
    "svc_lin_final   = best_svc_lin.fit(x_train_sub, y_train_sub) # good \n",
    "logreg_final    = best_logreg.fit(x_train_sub, y_train_sub)  # good\n",
    "lda_final       = best_lda.fit(x_train_sub, y_train_sub)\n",
    "sgd_final       = best_sgd.fit(x_train_sub, y_train_sub)\n",
    "\n",
    "print('all done!')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#=================================================\n",
    "#  ____               _ _      _   _             \n",
    "# |  _ \\ _ __ ___  __| (_) ___| |_(_) ___  _ __  \n",
    "# | |_) | '__/ _ \\/ _` | |/ __| __| |/ _ \\| '_ \\ \n",
    "# |  __/| | |  __/ (_| | | (__| |_| | (_) | | | |\n",
    "# |_|   |_|  \\___|\\__,_|_|\\___|\\__|_|\\___/|_| |_|\n",
    "#\n",
    "#================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process test data \n",
    "df_test  = pd.read_csv(file_test)\n",
    "\n",
    "# feats\n",
    "x_test   = df_test.iloc[:, 1:]\n",
    "\n",
    "# remove low var feats (as in x_train)\n",
    "x_test   = x_test[x_test.columns[selector_var.get_support(indices = True)]]\n",
    "\n",
    "# tweet id\n",
    "t_id     = df_test.id.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather models \n",
    "\n",
    "final_models = {'lda'      : lda_final,\n",
    "                'sgd'      : sgd_final,\n",
    "                'svc_lin'  : svc_lin_final,\n",
    "                'logreg'   : logreg_final}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all predictions completed!\n"
     ]
    }
   ],
   "source": [
    "#%% make prediction \n",
    "\n",
    "for name, model in final_models.items(): \n",
    "    \n",
    "    # make prediction \n",
    "    pred     = model.predict(x_test)\n",
    "    \n",
    "    # convert to text labels\n",
    "    pred     = ['SARCASM' if i == 1 else 'NOT_SARCASM' for i in pred]\n",
    "    \n",
    "    pred     = pd.DataFrame(pred, columns = ['predictions'])\n",
    "\n",
    "    # concat into df\n",
    "    answer   = pd.concat([t_id, pred], axis = 1)\n",
    "    \n",
    "    # construct file name \n",
    "    file_ans = Path(os.path.join(os.getcwd(), 'answer_split_' + name + '.txt'))\n",
    "    \n",
    "    # name the file, based on the classifier\n",
    "    answer.to_csv(file_ans, header = None, index = None, sep = ',')\n",
    "    \n",
    "print('all predictions completed!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
